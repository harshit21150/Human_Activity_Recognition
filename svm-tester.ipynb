{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3733921,"sourceType":"datasetVersion","datasetId":2232355}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pickle\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-28T13:24:25.706945Z","iopub.execute_input":"2023-11-28T13:24:25.707713Z","iopub.status.idle":"2023-11-28T13:24:41.116541Z","shell.execute_reply.started":"2023-11-28T13:24:25.707669Z","shell.execute_reply":"2023-11-28T13:24:41.115648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Here we have called vgg16 for its implementation before extraction .\n# Got to know about it from this blog\n# link:- https://franky07724-57962.medium.com/using-keras-pre-trained-models-for-feature-extraction-in-image-clustering-a142c6cdf5b1#:~:text=Using%20Keras'%20Pre%2Dtrained%20Models%20for%20Feature%20Extraction%20in%20Image%20Clustering,-franky&text=Keras%20provides%20a%20set%20of,feature%20extraction%2C%20and%20transfer%20learning.\n\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(220, 220, 3)) # Using 3 for dimensional aspect\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T13:24:43.211685Z","iopub.execute_input":"2023-11-28T13:24:43.212934Z","iopub.status.idle":"2023-11-28T13:24:47.242393Z","shell.execute_reply.started":"2023-11-28T13:24:43.212898Z","shell.execute_reply":"2023-11-28T13:24:47.241447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#References used to work with vgg16\n#We used img_to_array func from keras library, becuase there was a shape issue happening during extraction\n#link:- https://www.tensorflow.org/api_docs/python/tf/keras/utils/img_to_array\n#Used this blog for code and pre-processing implementation\n#link: https://franky07724-57962.medium.com/using-keras-pre-trained-models-for-feature-extraction-in-image-clustering-a142c6cdf5b1#:~:text=Using%20Keras'%20Pre%2Dtrained%20Models%20for%20Feature%20Extraction%20in%20Image%20Clustering,-franky&text=Keras%20provides%20a%20set%20of,feature%20extraction%2C%20and%20transfer%20learning.\n\ndef convo_features(img_path):\n    img = image.load_img(img_path, target_size=(220, 220))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    features = base_model.predict(x)\n    return features.flatten()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T13:24:55.222413Z","iopub.execute_input":"2023-11-28T13:24:55.222812Z","iopub.status.idle":"2023-11-28T13:24:55.229010Z","shell.execute_reply.started":"2023-11-28T13:24:55.222779Z","shell.execute_reply":"2023-11-28T13:24:55.227645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_csv = pd.read_csv('/kaggle/input/human-action-recognition-har-dataset/Human Action Recognition/Training_set.csv')\ntest_csv = pd.read_csv('/kaggle/input/human-action-recognition-har-dataset/Human Action Recognition/Testing_set.csv')\ntrain_path='/kaggle/input/human-action-recognition-har-dataset/Human Action Recognition/train'\ntest_path='/kaggle/input/human-action-recognition-har-dataset/Human Action Recognition/test/'\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T14:51:00.852723Z","iopub.execute_input":"2023-11-28T14:51:00.853241Z","iopub.status.idle":"2023-11-28T14:51:01.025256Z","shell.execute_reply.started":"2023-11-28T14:51:00.853204Z","shell.execute_reply":"2023-11-28T14:51:01.023355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_img_addr=[]\nall_label_addr=[]\n\n# Created 2 arrays using containing all image path and their mapped labels\nfor i in range(0, train_csv.shape[0]):\n        img_path = train_path +'/'+ train_csv['filename'][i]\n        label_path= train_csv['label'][i]\n        all_img_addr.append(img_path)\n        all_label_addr.append(label_path)\n        \nprint(len(all_img_addr))\nprint(len(all_label_addr))","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:52:55.978146Z","iopub.execute_input":"2023-11-26T17:52:55.978594Z","iopub.status.idle":"2023-11-26T17:52:56.294409Z","shell.execute_reply.started":"2023-11-26T17:52:55.978559Z","shell.execute_reply":"2023-11-26T17:52:56.293257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_img_addr[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:52:58.189141Z","iopub.execute_input":"2023-11-26T17:52:58.189563Z","iopub.status.idle":"2023-11-26T17:52:58.199841Z","shell.execute_reply.started":"2023-11-26T17:52:58.189531Z","shell.execute_reply":"2023-11-26T17:52:58.198513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nconvo_feat = all_img_addr\nfinal_labels = all_label_addr\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:52:59.885144Z","iopub.execute_input":"2023-11-26T17:52:59.885548Z","iopub.status.idle":"2023-11-26T17:52:59.891487Z","shell.execute_reply.started":"2023-11-26T17:52:59.885519Z","shell.execute_reply":"2023-11-26T17:52:59.889957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Note:- Main feature extraction is happening here, every image addr is going insider convo_features_func() and featires are getting extracted\ntemp_convo_features = [convo_features(i) for i in convo_feat]\n\n# converting to numpy arrays, as numpy arrays are accpetable in SVM's\nnumpy_convo_features = np.array(temp_convo_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Splitting dataset and validating training sets creation\nmain_features, main_test_feat, main_train_label, main_test_label = train_test_split(numpy_convo_features, final_labels, test_size=0.2, random_state=42)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(numpy_convo_features[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:33:47.357357Z","iopub.execute_input":"2023-11-26T09:33:47.360092Z","iopub.status.idle":"2023-11-26T09:33:47.367042Z","shell.execute_reply.started":"2023-11-26T09:33:47.360022Z","shell.execute_reply":"2023-11-26T09:33:47.365131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Reducing Dimensions using PCA at saving 95% varianve\npca = PCA(n_components=0.95)\ntrain_pca = pca.fit_transform(main_features)\ntest_pca = pca.transform(main_test_feat)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:33:53.716987Z","iopub.execute_input":"2023-11-26T09:33:53.717423Z","iopub.status.idle":"2023-11-26T09:41:25.109387Z","shell.execute_reply.started":"2023-11-26T09:33:53.717395Z","shell.execute_reply":"2023-11-26T09:41:25.108522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"C_val=[0.1,1]\nkernel_val=['rbf','linear']\n\n# Called and initiated SVM classifier\nsvm_convo_model = SVC(C=C_val[1], kernel=kernel_val[0]) # keeping gamma default as scaled gamma was giving low accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:54:05.268597Z","iopub.execute_input":"2023-11-26T17:54:05.269037Z","iopub.status.idle":"2023-11-26T17:54:05.275134Z","shell.execute_reply.started":"2023-11-26T17:54:05.269005Z","shell.execute_reply":"2023-11-26T17:54:05.274181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_convo_model.fit(train_pca, main_train_label)  # Training model by fitting training data got after spllting data\n\n# checking trained model using splitted test_data\naccuracy = svm_convo_model.score(test_pca, main_test_label)\nprint(f'Accuracy for linear SVM: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:25:36.755944Z","iopub.execute_input":"2023-11-26T10:25:36.756374Z","iopub.status.idle":"2023-11-26T10:35:42.075310Z","shell.execute_reply.started":"2023-11-26T10:25:36.756341Z","shell.execute_reply":"2023-11-26T10:35:42.073998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Note:- this method to save model and download it for further use, i learnt it using chatgpt as other methods were giving some error\nwith open('svm_model_rbf_dummy.pkl', 'wb') as svm_model_file:\n    pickle.dump(svm_convo_model, svm_model_file)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:49:41.726827Z","iopub.execute_input":"2023-11-26T11:49:41.727154Z","iopub.status.idle":"2023-11-26T11:49:42.257933Z","shell.execute_reply.started":"2023-11-26T11:49:41.727129Z","shell.execute_reply":"2023-11-26T11:49:42.256322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwith open('pca_model_1.pkl', 'wb') as pca_model_file:\n    pickle.dump(pca, pca_model_file)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:50:06.554035Z","iopub.execute_input":"2023-11-26T11:50:06.554626Z","iopub.status.idle":"2023-11-26T11:50:06.563083Z","shell.execute_reply.started":"2023-11-26T11:50:06.554581Z","shell.execute_reply":"2023-11-26T11:50:06.560668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nextracted_feature_tester=convo_features('/kaggle/input/human-action-recognition-har-dataset/Human Action Recognition/train/Image_1.jpg')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:49:20.862051Z","iopub.execute_input":"2023-11-26T11:49:20.862432Z","iopub.status.idle":"2023-11-26T11:49:21.177343Z","shell.execute_reply.started":"2023-11-26T11:49:20.862407Z","shell.execute_reply":"2023-11-26T11:49:21.176407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}